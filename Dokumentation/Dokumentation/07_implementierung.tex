\chapter{Implementierung}
\label{ch:Implementierung}

\section{Hostsystem}
\label{sec:Hostsystem}

\subsection{Grundkonfiguration}
\label{subsec:Grundkonfiguration}

Als Hostsystem kommt ein Debian x.y 64-Bit zum Einsatz. Dieses System ist ein virtuelles System welches auch als vServer bezeichnet wird. Bereitgestellt wird dieser vServer von providerdienste.de\footnote{\url{https://www.providerdienste.de/}} mit folgenden Eigenschaften:

\begin{itemize}
\item 2 CPU-Kerne %TODO a xy - Takt o.ä. hinzufügen
\item 2 GB Arbeitsspeicher
\item 50 GB Festplatte
\item 1 IPv4-Adresse
%\item 10 Ipv6-Adressen
\end{itemize}

Das System wurde mit diesen Eigenschaften gewählt, um sicherzustellen, das für diesen Versuchsaufbau ausreichend Rechenleistung und Speicher zur Verfügung steht. Zudem ist die öffentliche IPv4-Adresse zu nennen, die den Teammitgliedern in einem Versuchsaufbau in einem privaten Heimnetzwerk aus technischen Gründen nicht zur Verfügung gestanden hat. Die Verwaltung des Servers erfolgt über einen Root-Zugang .. %TODO
Alternative ist eine Verwaltung über eine sogenannte Remote-Konsole möglich. Über diese Konsole  kann das System jederzeit gestartet und gestoppt werden, selbst dann wenn kein Zugriff via SSH zur Verfügung steht.\\

Um das System nach der Übergabe durch providerdienste.de auf einen aktuellen Stand zu bringen, wird ein Update der installierten Pakete durchgeführt. Dazu werden die Paketlisten neu eingelesen und neue Paketversionen installiert:

\begin{lstlisting}[style=customc]
apt-get update && apt-get upgrade
\end{lstlisting}

Um nicht ausschließlich mit root-Rechten zu arbeiten wird für jedes Teammitglied ein eigener Benutzer mit Homeverzeichnis eingerichtet:

\begin{lstlisting}[style=customc]
useradd -d /home/mstroh -s /bin/bash -m mstroh
useradd -d /home/dschwenk -s /bin/bash -m dschwenk
\end{lstlisting}

Um diesen Benutzern die Ausführung von Kommandos mit root-Rechten dennoch zu ermöglichen, werden diese Benutzer in die Gruppe \textit{sudo} aufgenommen

\begin{lstlisting}[style=customc]
sudo adduser mstroh sudo
sudo adduser dschwenk sudo
\end{lstlisting}

Damit ist die Grundkonfiguration des vServers abgeschlossen. %TODO .. wirklich? fehlt  noch was? netzwerkconfig o.ä?


\subsection{Konfiguration Serverdienste}
\label{subsec:Konfiguration Serverdienste}

- Konfiguation von Diensten wie SSH (Public Key Authentifizierung einrichten)\\
- beachten, dass Server-SSH-Dienst von Port 22 auf anderen Port gelegt wird (z.b 10022), da Honeypot-SSH-Dienst auf Port 22 laufen sollte\\
- vielelicht hinweis, dass über port scanner der normale ssh dienst trotzdem gefunden wird\\

Das System wurde von providerdienste.de mit einem aktiven SSH-Dienst ausgeliefert. ..\\

Damit eine Authentifizieurng stattfinden kann, muss im Benutzerverzeichnis der Teammitglieder auf dem Server ein .ssh-Verzeichnis angelegt werden. In diese Verzeichnise wird jeweils der öffentliche Schlüssel in die Datei \textit{authorized\_keys} abegelegt.

\begin{lstlisting}[style=customc]
cat .ssh/id_dsa.pub | ssh heinz@server 'cat >> .ssh/authorized_keys'
\end{lstlisting}


Um die Authentifizierung via Passwort zu deaktivieren wird die die \textit{sshd\_config} unter \textit{/etc/ssh/} wie folgt angepasst:

\begin{lstlisting}[style=customc]
ChallengeResponseAuthentication no
PasswordAuthentication no
UsePAM no
\end{lstlisting}

Ebenfalls wird der Parameter \textit{PermitRootLogin} auf \textit{no} gesetzt, um einen zukünftigen Login des root-Benutzers zu deaktivieren. Abschließend wird der SSH-Dienst mit einem

\begin{lstlisting}[style=customc]
service ssh restart
\end{lstlisting}

neugestartet. Von nun an ist nur noch eine Anmeldung über die Benutzeraccounts der Teammitglieder in Kombination mit einer Public-Key-Authentifizierung möglich.

\section{SSH-Honeypot}
\label{sec:SSH-Honeypot}

\subsection{Installation und Konfiguration Kippo}
\label{subsec:Installation und Konfiguration Kippo}

% vorgehenseise installation + konfiguration kippo\\
% http://www.blackhat.pm/ssh-honeypot-on-debian-with-kippo.html
% https://technik.blogbasis.net/kippo-ssh-honeypot-installieren-17-10-2014

% ausführliche Beschreibung Kippo + Dateien\\
% http://resources.infosecinstitute.com/tracking-attackers-honeypot-part-2-kippo/

Dieses Kapitel beschreibt die Vorgehensweise zur Installation und Konfiguration von einem SSH-Honeypot auf Basis von Kippo. Dieser SSH-Honeypot soll wie für SSH üblich auf Port 22 eingerichtet werden. Da aktuell der standard SSH-Dienst auf Port 22 läuft, muss dieser zuvor angepasst werden. Dazu wird der Port in der Konfigurationsdatei \textit{etc/ssh/sshd\_config} auf Port 10022 abgeändert und der Dienst anschließend via \textit{service sshd restart} neugestartet.

Damit Kippo lauffähig ist, sind einige zusätzliche Pakete notwendig\footnote{ Kippo Abhängigkeiten: \url{https://github.com/desaster/kippo\#requirements}}. Diese werden, ebenso wie der git-Client für einen einfachen Download des Kippo-Projekts, installiert:

\begin{lstlisting}[style=customc]
apt-get install python-dev openssl python-openssl python-pyasn1 
  python-twisted git
\end{lstlisting}

Einer Ausführung von Befehlen oder Diensten mit root-Rechten sollte stets wohl bedacht sein und nach Möglichkeit vermieden werden. Die Ausführung des Honeypot-SSH-Dienstes mit root-Rechten oder auch unter einem unserer Benutzer wäre höchst sicherheitskritisch. Ein Angreifer könnte darüber volle Kontrolle über das Hostsystem erlangen. Um diese Gefahr möglichst gering zu halten wird ein separater Benutzer eingerichtet:

\begin{lstlisting}[style=customc]
useradd -d /home/kippo -s /bin/bash -m kippo -g sudo
\end{lstlisting}

Um auf einem Linux-System einen Port kleiner 1024 ("`well known ports"') zu verwenden sind root-Rechte erforderlich. Genau dies soll für den SSH-Honeypot-Dienst wie oben beschrieben vermieden werden. Um auch einem normalen Benutzer die Verwendung eines Ports kleiner 1024 zu ermöglichen, wird auf das Programm \textit{AuthBind}\footnote{ \textit{AuthBind}: \url{http://man.cx/authbind(1)}} zurückgegriffen. AuthBind ermöglicht es auch Benutzern auf priviliergte Ports zuzugreifen. Die Installation von Authbind erfolgt via:

\begin{lstlisting}[style=customc]
apt-get install authbind
\end{lstlisting}

Die Verwendung von Port 22 wird über die Erstellung einer Datei unter \textit{/etc/authbind/byport/} sowie die Anpassung der Berechtigungen für den Kippo-Benutzer auf diese Datei ermöglicht:

\begin{lstlisting}[style=customc]
touch /etc/authbind/byport/22
chown kippo /etc/authbind/byport/22
chmod 777 /etc/authbind/byport/22
\end{lstlisting}

Der Download von Kippo erfolgt direkt von der Projektseite auf Github\footnote{ \textit{Kippo-Projekt auf Github}: \url{https://github.com/desaster/kippo}}:

\begin{lstlisting}[style=customc]
git clone https://github.com/desaster/kippo.git
\end{lstlisting}

Im Kippo-Verzeichnis befindet sich eine Datei, die eine Standardkonfiguration enthält. In dieser wird der  voreingestellte Port auf Port 22 abgeändert. Zudem muss die Konfigurationsdatei in \textit{kippo.cfg} umbenannt werden:

\begin{lstlisting}[style=customc]
mv kippo.cfg.dist kippo.cfg
\end{lstlisting}

Damit Kippo mit Hilfe von AuthBind ausgeführt wird, muss das "`Kippo-Start-Skript"' angepasst werden. Dazu wird der Befehl \textit{authbind} in das Skript aufgenommen:

\begin{lstlisting}[style=customc]
authbind --deep twistd -y kippo.tac -l log/kippo.log --pidfile kippo.pid
\end{lstlisting}

Der Parameter \textit{--deep} sorgt dafür, dass nicht nur das direkt folgende Programm, sondern auch alle Programme die folge dieses Aufrufs sind, unter \textit{authbind} ausgeführt werden. twistd, xy, wird zudem eine Logdatei sowie ein Pidfile übergeben. In diesem wird die Prozess-ID abgelegt.

Parameter erklären ...\\

Nach Ausführung des "`Kippo-Start-Skript"' läuft der Prozess im Hintergrund. In Folge dessen wird auch das Kippo-Logfile angelegt, in dem Zugriffe auf den SSH-Honeypot-Dienst dokumentiert werden. Änderungen in diesem Logfile können über

\begin{lstlisting}[style=customc]
tail -f /home/kippo/kippo/log/
\end{lstlisting}

direkt verfolgt werden. Von nun an kann auch eine Verbindung auf Port 22 aufgebaut werden:

Die Anpassung des Banners kann in der Konfigurationsdatei von Kippo vorgenommen werden.

Nicht zu vergessen ist, dass der SSH-Dienst auf Port 10022, der die Verbindung der Projektmitarbeiter ermöglicht, durch einen Portscanner wie NMap aufgespürt werden kann.

\subsection{Kippo-Logfile auswerten}
\label{subsec:Kippo-Logfile auswerten}

% - extract uniq ips aus kippo logfile \\
% https://bruteforce.gr/extracting-unique-ips-from-logfile.html \\

Die IP-Adressen von Angreifern werden im Kippo.log-Logfile neben zahlreichen Informationen wie eingegeben Benutzernamen, Passwörter und Befehle gespeichert. Ein Auszug aus einem Kippo-Logfile ist im Anhang unter x zu finden. Aus diesen Informationen sollen Statistiken zu Benutzernamen und Passwörter sowie automatisiert Firewallregeln erstellt werden, um Angriffe von diesen IPs zeitweise zu verhindern.

Wie dem Kippo-Logfile unter x.y zu entnehmen ist, werden Benutzernamen und Passwörter als Teile von Zeichenketten im Logfile abgelegt. Für eine Auswertung müssen diese aus dem Logfile extrahiert werden. Dies erfolgt mit Hilfe der Werkzeuge \textit{grep} und \textit{awk}. Duplikate werden durch \textit{sort} und \textit{uniq} entfernt.


% http://bob.k6rtm.net/kippowho.html

\begin{lstlisting}[style=customc]
grep ' login attempt ' kippo.log |
  awk '{print ($9)}' |
  sort |
  uniq > user.txt
\end{lstlisting}

Ebenfalls werden Passwörter extrahiert:

\begin{lstlisting}[style=customc]
grep ' login attempt ' kippo.log |
  awk '{print ($9)}' |
  sed "s|^.*/||g" |
  sed "s|]||g" > pw.txt
\end{lstlisting}

Passwortduplikate werden hierbei nicht entfernt, um daraus aussagekräftige Statistiken generieren zu können.


- Auswertung der Passwörter (diese müssen zuerst geparst werden)\\
% https://github.com/digininja/pipal
% https://digi.ninja/blog/pipal_kippo.php
- alternativ Kippo Graph
% https://github.com/ikoniaris/kippo-graph

\subsection{Firewallregeln erstellen}
\label{subsec:Firewallregeln erstellen}

Ziel unseres System ist es, einen Angreifer zu beobachten und aus seinem Vorgehen zu lernen. Anschließend soll der Angreifer von der Infrastruktur fern gehalten werden, um die Sicherheit anderer Systeme zu wahren. Um einen Angreifer wirkungsvoll von einer Infrastruktur fernzuhalten, besteht die Möglichkeit den Datenverkehr des Angreifers mit einer Firewall, die dieser Infrastruktur vorgelagert ist, zu blockieren. Da in dem vorliegenden Versuchsaufbau keine weiterreichende Infrastruktur mit einer vorgelagerten Firewall vorhanden ist, wird hier exemplarisch auf dem Honeypotsystem selbst die Abwehr der Datenpakete des Angreifers mit Hilfe von \textit{iptables} vorgenommen. Die Wahl fällt auf \textit{iptables}, da hiermit Firwallregeln über sogenannte Ketten von Regeln erstellt werden können. Zudem ist \textit{iptables} standardmäßig unter Debian verfügbar und kann über ein Bash-Skript automatisiert werden. 

Um Firewallregeln generieren zu können, müssen die IP-Adressen der Angreifer aus dem Kippo-Logfile extrahiert werden. Dies geschieht wie bereits unter \ref{subsec:Kippo-Logfile auswerten} beschrieben mit Hilfe der Werkzeuge \textit{grep}, \textit{sort} und \textit{uniq}. Dazu wird an \textit{grep} ein regulären Ausdruck übergeben, der IP-Adressen filtert. Damit keine identischen Firewallregeln erzeugt werden, werden doppelte IP-Adressen entfernt.

\begin{lstlisting}[style=customc]
cat logfile.log | 
  grep -o '[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}' |
  sort |
  uniq > unique-ips.txt
\end{lstlisting}

Die Generierung der Firwallregeln geschieht automatisiert über nachfolgendes Skript:

\begin{lstlisting}[style=customc]
#!/bin/bash
#
# set variables
FW="/sbin/iptables"
IPFILE="/home/dschwenk/ipfile.txt"
BACKUPFILE="/home/dschwenk/backupfile.txt"

# backup current rules
iptables-save > $BACKUPFILE

# delete existing rules and chains
$FW -F
$FW -X

# set standard rules
$FW -P INPUT   ACCEPT
$FW -P FORWARD ACCEPT
$FW -P OUTPUT  ACCEPT

while read IP; do
  $FW -A INPUT -s $IP -j DROP
done < $IPFILE


\end{lstlisting}

Das Skript fertig zuerst über iptabales-save ein Backup der bestehenden Regeln an, welches wie unter \ref{subsec:Archivierung von Daten} beschrieben archiviert wird. Eine beispielhafte Ausgabe von iptables-save ist im Anhang unter x.y zu finden. Anschließend werden alle existierenden Regeln gelöscht. Dies geschieht explizit, um mögliche false positives, die durch dynamische IP-Adressen zustanden kommen können, nicht dauerhaft zu blockieren. Ebenfalls explizit werden über die Regeln standardmäßig alle Verbindungen akzeptiert. Damit lassen sich aus den Verbindungs-Logfiles beispielsweise Portscans nachweisen.

Dieses Skript wird über einen cronjob einmal täglich ausgeführt.


\section{Web-Honeypot}
\label{sec:Web-Honeypot}


\section{sonstiges}
\label{sec:sonstiges}

- passende überschriften finden\\
- archivieren von logfiles\\
- benachrichtigung bie angriff\\
- reverse lookup ip -adressen (+ darstellung auf karte? geo-ip?\\

\subsection{Archivierung von Daten}
\label{subsec:Archivierung von Daten}

Um der Soll-Anforderung nach der Archivierung von Logdaten sowie Analyseergebnisse zu entsprechen, werden diese Daten automatisiert auf einem Cloud-Speicher abgelegt. Dieses Archivierung stellt sicher, dass auf diese Daten selbst dann zurückgegriffen werden kann, wenn das System kompromittiert wurde oder nicht weiter zur Verfügung steht. Eine Marktanalyse ergibt eine Vielzahl an verfügbaren Cloud-Speichern. Das Projektteam entscheidet sich auf Grund der Verfügbarkeit eines Linux-Clients, der einfachen Installation und Konfiguration dieses Clients sowie dessen Möglichkeit zur automatischen Ausführung via Kommandozeile für Google Drive\footnote{ Google Drive: \url{https://www.google.com/intl/de_de/drive/}}. Anzumerken ist, dass dieser Client nicht von Google selbst, sondern von Petter Rasmussen in einem open source Projekt entwickelt wird\footnote{ Peter Rasmussen gDrive command line tool: \url{https://github.com/prasmussen/gdrive}}. Der Download der aktuellen Version 2.1 des 64-Bit-Clients für Linux erfolgt durch:

\begin{lstlisting}[style=customc]
wget https://docs.google.com/uc?id=0B3X9GlR6EmbnQ0FtZmJJUXEyRTA&export=download
\end{lstlisting}

Durch eine Umbennung wird der kryptische Dateiname lesbar gemacht. Zudem wird die Datei als ausführbar markiert:

\begin{lstlisting}[style=customc]
mv 0B3X9GlR6EmbnQ0FtZmJJUXEyRTA&export gdrive
chmod +x gdrive
\end{lstlisting}

Die Installation erfolgt via:

\begin{lstlisting}[style=customc]
sudo install gdrive /usr/local/bin/gdrive
\end{lstlisting}

Nach der erfolgreichen Installation des Clients müssen diesem Berechtigungen zum Zugriff auf einen Google Drive Account eingerichtet werden. Dazu wird der Client mit einem beliebigen Parameter aufgerufen:

\begin{lstlisting}[style=customc]
gdrive list
\end{lstlisting}

Infolge dessen wird eine Aufforderung zum Besuch der Google-Drive-Website zur Authentifizierung ausgegeben. Somit ist eine Verbindung zwischen dem Client und dem Google Drive-Dienst hergestellt.

In die Archivierung fließen sämtliche Log- und Analysedaten sowie Konfigurationsdateien ein. Dazu gehören:

\begin{itemize}
\item Kippo-Konfiguration und Logfile
\item x.y Logfile
\item Auswertung der Benutzer- und Passwortdaten
\item Auswertung der IP-Adressen
\item Konfigurationsdateien von iptables
\end{itemize}

Für einen effizienten Upload werden die oben genannten Dateien alle 24 Stunden zu einem komprimierten zip-Archiv zusammengefasst und auf den Cloud-Speicher hochgeladen. Um diesen Vorgang zu automatisieren wird folgendes Bash-Skript angelegt:

\begin{lstlisting}[style=customc]
#!/bin/bash
#
# set up variables
DATE=`date +%Y%m%d_%H-%M`
FILENAME=$DATE_backup.tar.gz

# create zip archive
tar xyz $FILENAME

# upload zip archive
gdrive upload $FILENAME
\end{lstlisting}

Ausgeführt wird dieses Skript täglich um 6:00 Uhr mit Hilfe eines cronjobs. Die Übertragung der Daten erfolgt verschlüsselt. Ein möglicher Angreifer kann so den Datenstrom nicht nachvollziehen. %TODO .. wirklich? .. man in the middle?
